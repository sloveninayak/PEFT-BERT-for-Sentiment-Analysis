{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sloveninayak/peft-bert/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pXxX-4xREhaY"
      },
      "outputs": [],
      "source": [
        "!pip install -q \"datasets==2.15.0\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j9td5vykIgBT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4956fb90-f817-42b8-f1a3-f6b0968211d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "#FROM TRANSFORMERS LIBRARY, LOAD SST2 DATASET STANFORD SENTIMENT TREEBANK\n",
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"stanfordnlp/sst2\", split=\"train\").train_test_split(test_size=0.2, shuffle=True, seed=23)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JBtIMPI3IgGu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1303e7b1-6c08-467c-8549-a253f4be5c2c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['idx', 'sentence', 'label'],\n",
              "    num_rows: 53879\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "#TRAIN-TEST SPLIT ON LOADED DATASET\n",
        "splits = [\"train\", \"test\"]\n",
        "dataset[\"train\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IWysBfcCIgM3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72400abe-6dbf-41ff-e574-d8f9bf720dc9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'idx': 14677, 'sentence': 'good performances ', 'label': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "#LABEL1 NEGATIVE\n",
        "#LABEL2 POSITIVE\n",
        "dataset[\"train\"][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gxHmGdZVIgTO"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "#TOKENIZE TEXT DATA, CONVERT TEXT INTO NUMERICAL REPRESENTATIONS\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "from transformers import DataCollatorWithPadding, Trainer, TrainingArguments\n",
        "#PREPARE BATCHES OF DATA FOR TRAINING, PERFORM PADDING SEQ TO FIXED LENGTH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aul7Vhr2JvAh"
      },
      "outputs": [],
      "source": [
        "#DOES NOT PERFORM CASE SENSITIVITY DURING TOKENIZATION\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mWa_BQSyJvDZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d60ba4df-8c29-4086-99e1-667cb4ab1d24"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['idx', 'sentence', 'label', 'input_ids', 'attention_mask'],\n",
              "    num_rows: 53879\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "tokenized_dataset = {}\n",
        "for split in splits: tokenized_dataset[split] = dataset[split].map(lambda x: tokenizer(x[\"sentence\"], truncation=True), batched=True)\n",
        "tokenized_dataset[\"train\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "28UqSFF_JvGd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "242f34f9-1972-4247-fb43-01fa6eccf834"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=768, out_features=2, bias=True)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "#WE USED LAMBDA FUNC TO TOKENIZE, INSPECTED AVAILABLE COLUMNS\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\",num_labels=2,id2label={0: \"negative\", 1: \"positive\"},label2id={\"negative\": 0, \"positive\": 1})\n",
        "#FREEZE WEIGHTS OF PRETRAINED MODEL LAYERS AND ONLY TRAIN CLASSIFIER LAYER\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = True\n",
        "model.classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IZY7xqsPJvJq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36ca3be3-3cb9-4699-f936-e3868a1dfef3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DistilBertForSequenceClassification(\n",
            "  (distilbert): DistilBertModel(\n",
            "    (embeddings): Embeddings(\n",
            "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
            "      (position_embeddings): Embedding(512, 768)\n",
            "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (transformer): Transformer(\n",
            "      (layer): ModuleList(\n",
            "        (0-5): 6 x TransformerBlock(\n",
            "          (attention): MultiHeadSelfAttention(\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "          )\n",
            "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (ffn): FFN(\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (activation): GELUActivation()\n",
            "          )\n",
            "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
            "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
            "  (dropout): Dropout(p=0.2, inplace=False)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "byhnljwaKF4I"
      },
      "outputs": [],
      "source": [
        "#CALC ACCURACY METRIC FOR SENTIMENT ANALYSIS\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    #ASSUMES PRED IS NUMPY ARRAY CONTAINING PROBABILITIES OR LOGITS FOR EACH CLS\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    return {\"accuracy\": (predictions == labels).mean()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKstHSdPKGEG",
        "outputId": "3134215d-53db-4fa5-ecbd-fc84ff8dc217"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.40.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.2.1+cu121)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.30.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->transformers[torch]) (12.4.127)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->transformers[torch]) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->transformers[torch]) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "pip install transformers[torch]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-LnYJFNXKGHi",
        "outputId": "790f5ebd-26ea-4c86-916d-dd4e68723967"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.30.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.2.1+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "pip install accelerate -U"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HZ2xrZ1LKF7o",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "84355ee4-c0c7-48bd-c96b-c7289bbd810c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3368' max='3368' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3368/3368 11:12]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_loss': 0.6889376044273376,\n",
              " 'eval_accuracy': 0.5520415738678545,\n",
              " 'eval_runtime': 673.043,\n",
              " 'eval_samples_per_second': 20.014,\n",
              " 'eval_steps_per_second': 5.004}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "#CREATES TRAINER OBJECT FROM TRANSFORMERS LIBRARY TO TRAIN\n",
        "trainer = Trainer(model=model,\n",
        "    args=TrainingArguments(\n",
        "        output_dir=\"./data/spam_not_spam\",\n",
        "        #SET LEARNING RATE TO COMMON STARTING POINT\n",
        "        learning_rate=2e-3,\n",
        "        #SET PER DEVICE TRAIN BATCH SIZE AND EVAL BATCH SIZE\n",
        "        per_device_train_batch_size=4,\n",
        "        #MODEL PROCESS 4 SAMPLES AT TIME DURING TRAINING AND EVALUATION\n",
        "        per_device_eval_batch_size=4,\n",
        "        #EVALUATE AND SAVE THE MODEL AFTER EACH EPOCH\n",
        "        evaluation_strategy=\"epoch\",\n",
        "        #SAVE CHECKPOINT OF MODEL AFTER EACH TRAINING EPOCH\n",
        "        save_strategy=\"epoch\",\n",
        "        num_train_epochs=1,\n",
        "        #TO PREVENT OVERFITTING\n",
        "        weight_decay=0.01,\n",
        "        load_best_model_at_end=True,\n",
        "    ),\n",
        "    train_dataset=tokenized_dataset[\"train\"],\n",
        "    eval_dataset=tokenized_dataset[\"test\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "#EVALUATE BEFORE TRAINING\n",
        "trainer.evaluate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5RpPXBFjMn_s",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "c96d8ea3-0ffa-4a18-e5be-e89a95276bdc"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.8571428571428571\n",
            "Recall: 0.8571428571428571\n",
            "F1 Score: 0.8571428571428571\n"
          ]
        }
      ],
      "source": [
        "#LIKELY A METHOD PROVIDED BY TRANSFORMERS LIBRARY FOR SELECTING SPECIFIC ELEMENT\n",
        "items_for_manual_review = tokenized_dataset[\"test\"].select([0, 1, 22, 31, 43, 292, 448, 487])\n",
        "results = trainer.predict(items_for_manual_review)\n",
        "#CALC PRECISION, RECALL, F1 SCORE\n",
        "def calculate_precision_recall_f1(actuals, predictions):\n",
        "    true_positives = 0\n",
        "    false_positives = 0\n",
        "    false_negatives = 0\n",
        "\n",
        "    for actual, predicted in zip(actuals, predictions):\n",
        "        if actual == predicted == 1: true_positives += 1\n",
        "        if predicted == 1 and actual != predicted: false_positives += 1\n",
        "        if predicted == 0 and actual != predicted: false_negatives += 1\n",
        "    #PRECISION MEASURES PROPORTION OF POSITIVE PREDICTIONS THAT WERE ACTUALL CORRECT\n",
        "    precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0\n",
        "    recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0\n",
        "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "    return precision, recall, f1_score\n",
        "#CALC PERFORMANCE OF SENTIMENT ANALYSIS\n",
        "precision, recall, f1, = calculate_precision_recall_f1(results.label_ids, results.predictions.argmax(axis=1))\n",
        "\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1 Score: {f1}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lbV9wHCKCcN3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "nU8XyFjCMoC_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "07956bf9-1103-48fb-d9c2-d61124ed07d6"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'trainer' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-3435b262f1ae>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'trainer' is not defined"
          ]
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AAZYFEh7PDNc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YPrFjdPFMoGp"
      },
      "outputs": [],
      "source": [
        "trainer.evaluate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "alkl7Ye_duHQ"
      },
      "outputs": [],
      "source": [
        "pip install peft"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "94JURROJMoKU"
      },
      "outputs": [],
      "source": [
        "#PEFT FOR REDUCING MEMORY USAGE, TRAINING TIME, AND POTENTIALLY IMPROVING MODEL GENERALIZABILITY\n",
        "#LoraConfig SPECIFY NO. OF ADAPTER LAYERS, THEIR DIMENSIONS, AND OTHER HYPERPARAMETERS FOR PEFT\n",
        "#THEN AN ENUMERATION THAT DEFINES DIFFERENT TYPES OF TASKS SUPPORTED BY peft LIB\n",
        "from peft import (LoraConfig, get_peft_model, TaskType, PeftModel)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oKCJdMlPOIvu"
      },
      "outputs": [],
      "source": [
        "#DEFINE LoRA CONFIGURATION; r SETS RANK OF LOWRANK; lora_aplha IS A SCALING FACTOR USED TO ADJUST CONTRIBUTION; lora_dropouts TO SPECIFY DROPOUT RATE TO APPLY TO OUTPUTS\n",
        "lora_config = LoraConfig(r=2, lora_alpha=16, lora_dropout=0.05, target_modules=[\"q_lin\", \"k_lin\",\"v_lin\"],bias='none', task_type=TaskType.SEQ_CLS)\n",
        "#GET LoRA-ENABLED MODEL\n",
        "peft_model = get_peft_model(model, lora_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l5qgw0TxOIzb"
      },
      "outputs": [],
      "source": [
        "#TRAIN WITH PEFT\n",
        "trainer = Trainer(model = peft_model, args=TrainingArguments(output_dir=\"./data/spam_not_spam\", learning_rate=2e-3,per_device_train_batch_size=4,per_device_eval_batch_size=4,evaluation_strategy=\"epoch\",save_strategy=\"epoch\",num_train_epochs=1,weight_decay=0.01,load_best_model_at_end=True,), train_dataset = tokenized_dataset[\"train\"], eval_dataset = tokenized_dataset[\"test\"],tokenizer = tokenizer,data_collator = DataCollatorWithPadding(tokenizer = tokenizer),compute_metrics = compute_metrics,)\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q2lx_S21OI2E"
      },
      "outputs": [],
      "source": [
        "peft_model.save_pretrained('./peft_model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2WDrBV2cOI5L"
      },
      "outputs": [],
      "source": [
        "trainer.evaluate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4UidaFmDOSbK"
      },
      "outputs": [],
      "source": [
        "precision, recall, f1, = calculate_precision_recall_f1(results.label_ids, results.predictions.argmax(axis=1))\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1 Score: {f1}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dVTJSP9aOSfT"
      },
      "outputs": [],
      "source": [
        "#PERFORMING INFERENCE WITH A PEFT MODEL\n",
        "loaded_peft_model = AutoModelForSequenceClassification.from_pretrained('./peft_model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oTWduFyzOSjg"
      },
      "outputs": [],
      "source": [
        "#DF WITH PREDICTIONS, TEXT AND LABELS\n",
        "items_for_manual_review = tokenized_dataset[\"test\"].select([0, 1, 22, 31, 43, 292, 448, 487])\n",
        "results = trainer.predict(items_for_manual_review)\n",
        "df = pd.DataFrame(\n",
        "    {\"sentiments\": [item[\"sentence\"] for item in items_for_manual_review],\"predictions\": results.predictions.argmax(axis=1),\"labels\": results.label_ids,}\n",
        ")\n",
        "pd.set_option(\"display.max_colwidth\", None)\n",
        "df"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMBshfEou5Bk/IPWsgVTHKr",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}